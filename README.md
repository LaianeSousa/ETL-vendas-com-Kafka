# ETL Vendas com Kafka

Bem-vindo ao **ETL Vendas com Kafka**, o projeto que transforma dados de vendas brutos em insights valiosos, utilizando o poder do Apache Kafka para garantir um fluxo de dados √°gil, escal√°vel e confi√°vel. Este README foi projetado para gui√°-lo atrav√©s do nosso universo de processamento de dados com um toque de criatividade e informa√ß√µes claras. 

---

## üöÄ Introdu√ß√£o
Imagine um sistema em que seus dados de vendas fluem como um rio constante, indo de sistemas de entrada brutos at√© a cria√ß√£o de dashboards poderosos e prontos para a tomada de decis√£o. Com **ETL Vendas com Kafka**, voc√™ pode:

- **Extrair** dados de m√∫ltiplas fontes, sejam elas bancos de dados, APIs ou arquivos.
- **Transformar** os dados aplicando filtros, agregando informa√ß√µes e limpando inconsist√™ncias.
- **Carregar** os dados processados em sistemas de armazenamento, prontos para serem analisados.

Tudo isso com a efici√™ncia do Apache Kafka como plataforma central de mensagens.

---

## üîç Vis√£o Geral da Arquitetura
Nossa solu√ß√£o √© dividida em tr√™s principais componentes:

1. **Producers (Extra√ß√£o)**
   - Capturam dados de fontes como APIs de e-commerce, bancos de dados ou sistemas ERP e os publicam em t√≥picos do Kafka.

2. **Streams (Transforma√ß√£o)**
   - Utilizam o Kafka Streams ou Apache Flink para processar os dados em tempo real, aplicando transforma√ß√µes e agregando informa√ß√µes.

3. **Consumers (Carregamento)**
   - Consomem os dados transformados e os armazenam em bancos de dados relacionais, NoSQL, ou data lakes para an√°lise.

**Fluxo:**

```
Fonte de Dados -> Kafka Producer -> Kafka Topics -> Kafka Streams -> Kafka Consumer -> Data Warehouse / Dashboard
```

---

## üåê Tecnologias Utilizadas

### Infraestrutura
- **AWS S3**: Armazenamento de arquivos de dados de vendas, atuando como a fonte de dados para ETL.
- **PostgreSQL**: Armazenamento de dados transformados, permitindo a recupera√ß√£o de dados em tempo real.
- **Docker**: Containeriza√ß√£o de servi√ßos para f√°cil implanta√ß√£o e gerenciamento.
- **Kafka**: Sistema de enfileiramento de mensagens para monitoramento e disparo de processos ETL.

### Ferramentas de Desenvolvimento e An√°lise
- **DBeaver**: Gerenciamento e consulta de banco de dados.

### Principais Bibliotecas Python
- **pandas**: Manipula√ß√£o e transforma√ß√£o de dados.
- **boto3**: SDK da AWS para Python, usado para interagir com o S3.
- **Faker**: Simula√ß√£o de dados de vendas.
- **pydantic**: Valida√ß√£o de dados, garantindo a qualidade dos dados em cada etapa do pipeline.
- **sqlalchemy**: ORM para inser√ß√£o de dados no PostgreSQL.
- **streamlit**: Dashboard de KPI em tempo real.
- **confluent_kafka**: Interface para Kafka, gerenciando a execu√ß√£o de ETL baseada em eventos.

---

## üîß Configura√ß√£o do Ambiente

### Requisitos
- Docker e Docker Compose instalados.
- Java 11+ (se voc√™ planeja trabalhar diretamente com Kafka Streams).
- Python 3.9+ (para scripts personalizados).

### Passos para Come√ßar
1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/seu-usuario/etl-vendas-com-kafka.git
   cd etl-vendas-com-kafka
   ```

2. Suba os containers Docker:
   ```bash
   docker-compose up
   ```

3. Configure os producers e consumers no arquivo `config/etl-config.yml`.

4. Execute os producers:
   ```bash
   python producers/sales_producer.py
   ```

5. Execute os consumers:
   ```bash
   python consumers/etl_consumer.py
   ```

6. Visualize os dados processados no Grafana acessando `http://localhost:3000`.

---

## üé® Customiza√ß√£o
Voc√™ pode personalizar facilmente:

- **T√≥picos Kafka**: Edite os nomes dos t√≥picos no arquivo `config/topics.yml`.
- **Transforma√ß√µes**: Adicione novas transforma√ß√µes no m√≥dulo `streams/transformations.py`.
- **Destinos**: Configure novos bancos de dados ou sistemas de armazenamento no Kafka Connect.

---

## üìö Documenta√ß√£o Adicional
Confira nossa [Wiki](https://github.com/seu-usuario/etl-vendas-com-kafka/wiki) para tutoriais detalhados, exemplos de c√≥digo e dicas para resolver problemas comuns.

---

## üåü Principais Benef√≠cios
- **Escalabilidade**: Processamento distribu√≠do para lidar com grandes volumes de dados.
- **Tempo Real**: Insights instant√¢neos com baixa lat√™ncia.
- **Modularidade**: Componentes desacoplados que facilitam a manuten√ß√£o e expans√£o.

---

## ‚ú® Contribui√ß√µes
Contribui√ß√µes s√£o bem-vindas! Siga os passos abaixo:

1. Fork este reposit√≥rio.
2. Crie um branch com sua feature ou corre√ß√£o: `git checkout -b minha-feature`.
3. Envie um pull request e aguarde nossa revis√£o.

---

## üí° Ideias Futuras
- Integra√ß√£o com Spark para processamento em lote.
- Uso de Machine Learning para prever tend√™ncias de vendas.
- Cria√ß√£o de API para consulta dos dados processados.

---

## üåç Sobre
Desenvolvido com ‚ù§Ô∏è por uma equipe apaixonada por dados e solu√ß√µes escal√°veis. Para d√∫vidas ou suporte, entre em contato pelo e-mail **suporte@etl-vendas.com**.

